#!/bin/bash
#SBATCH -J cluster_transcripts
#SBATCH -N 1 # number of nodes
#SBATCH -n 1 # number of cores
#SBATCH --mem=8G # memory pool for all cores
#SBATCH -t 0-48:00 # time (D-HH:MM)
#SBATCH -o slurm.%N.%j.out # STDOUT
#SBATCH -e slurm.%N.%j.err # STDERR
#SBATCH --mail-user=anna.tyler@jax.org
#SBATCH --mail-type=END
# delete everything in the results folder and then run this pipeline to get clean results
# it may need to be restarted more than once if it times out
# example use: sbatch HDMA 

cd $SLURM_SUBMIT_DIR

module load singularity

singularity exec ../../../Containers/R.sif R -e 'rmarkdown::render(here::here("Documents", "1a.Tissue_Expression.Rmd"))'


singularity exec ../../../Containers/R.sif R -e 'rmarkdown::render(here::here("Documents", "1b.Trait_Selection.Rmd"))'


singularity exec ../../../Containers/R.sif R -e 'rmarkdown::render(here::here("Documents", "2a.Kinship_Expression_Traits.Rmd"))'


singularity exec ../../../Containers/R.sif R -e 'rmarkdown::render(here::here("Documents", "3a.Imputation.Rmd"))'


singularity exec ../../../Containers/R.sif R -e 'rmarkdown::render(here::here("Documents", "3b.High_Dimensional_Mediation.Rmd"))'
